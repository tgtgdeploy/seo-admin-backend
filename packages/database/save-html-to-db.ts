/**
 * ä»ä¸‰ä¸ª website HTML æ–‡ä»¶ä¸­æå–å†…å®¹å¹¶å­˜å‚¨åˆ°æ•°æ®åº“
 * å­˜å‚¨åˆ° SpiderPoolSource è¡¨ä¸­ï¼Œä¾›èœ˜è››æ± é¡µé¢ç”Ÿæˆä½¿ç”¨
 */

import * as fs from 'fs'
import * as cheerio from 'cheerio'
import { PrismaClient } from '@prisma/client'

const prisma = new PrismaClient()

// HTML æ–‡ä»¶è·¯å¾„é…ç½®
const HTML_FILES = [
  {
    name: 'Website-1 ç”µæŠ¥ä¸­æ–‡ç‰ˆ',
    filePath: '/home/ubuntu/WebstormProjects/seo-website-1/ç”µæŠ¥ä¸­æ–‡ç‰ˆ - Telegramå®˜ç½‘2.html',
    description: 'Telegramå®˜ç½‘ - ç”µæŠ¥ä¸­æ–‡ç‰ˆå†…å®¹æº',
    baseKeywords: ['Telegram', 'ç”µæŠ¥', 'ç”µæŠ¥ä¸­æ–‡ç‰ˆ', 'Telegramä¸­æ–‡ç‰ˆ', 'TGçº¸é£æœº', 'Windows', 'Mac', 'Android', 'iOS']
  },
  {
    name: 'Website-2 çº¸é£æœº',
    filePath: '/home/ubuntu/WebstormProjects/seo-website-2/çº¸é£æœº3.html',
    description: 'çº¸é£æœº - TGé£æœºä¸‹è½½å†…å®¹æº',
    baseKeywords: ['çº¸é£æœº', 'TGé£æœº', 'Telegram', 'ç”µæŠ¥ä¸‹è½½', 'å®‰å“ç‰ˆ', 'Android', 'Apk', 'ç”µè„‘ç‰ˆ', 'æ¡Œé¢ç‰ˆ']
  },
  {
    name: 'Website-TG ä¸‹è½½ç«™',
    filePath: '/home/ubuntu/WebstormProjects/seo-website-tg/TGä¸­æ–‡çº¸é£æœº1/Telegramå®˜ç½‘ - Telegramä¸‹è½½.html',
    description: 'Telegramä¸‹è½½ - å®‰å…¨å³æ—¶é€šè®¯å†…å®¹æº',
    baseKeywords: ['Telegram', 'ç”µæŠ¥', 'Telegramä¸‹è½½', 'å®‰å…¨å³æ—¶é€šè®¯', 'éšç§', 'ç«¯åˆ°ç«¯åŠ å¯†', 'ç§˜å¯†èŠå¤©']
  }
]

interface ExtractedContent {
  name: string
  description: string
  filePath: string
  paragraphs: string[]
  headings: string[]
  keywords: string[]
  totalParagraphs: number
  totalHeadings: number
  totalKeywords: number
}

/**
 * æå–å•ä¸ª HTML æ–‡ä»¶çš„å†…å®¹
 */
function extractFromHTML(
  filePath: string,
  name: string,
  description: string,
  baseKeywords: string[]
): ExtractedContent {
  console.log(`\nğŸ“„ æ­£åœ¨å¤„ç†: ${name}`)
  console.log(`   æ–‡ä»¶è·¯å¾„: ${filePath}`)

  const html = fs.readFileSync(filePath, 'utf-8')
  const $ = cheerio.load(html)

  // æå–æ‰€æœ‰æ®µè½
  const paragraphs: string[] = []
  $('p, .content p, article p, .post-content p, div p, section p').each((_, el) => {
    const text = $(el).text().trim()
    // è¿‡æ»¤å¤ªçŸ­çš„æ®µè½å’ŒåŒ…å«å¤ªå¤šç‰¹æ®Šå­—ç¬¦çš„æ®µè½
    if (text.length > 20 && text.length < 1000) {
      paragraphs.push(text)
    }
  })

  // å»é‡æ®µè½
  const uniqueParagraphs = Array.from(new Set(paragraphs))

  // æå–æ ‡é¢˜
  const headings: string[] = []
  $('h1, h2, h3, h4, h5, h6').each((_, el) => {
    const text = $(el).text().trim()
    if (text.length > 0 && text.length < 200) {
      headings.push(text)
    }
  })

  // å»é‡æ ‡é¢˜
  const uniqueHeadings = Array.from(new Set(headings))

  // ä»å†…å®¹ä¸­æå–é¢å¤–çš„å…³é”®è¯
  const contentKeywords = extractKeywordsFromText([...uniqueParagraphs, ...uniqueHeadings].join(' '))

  // åˆå¹¶åŸºç¡€å…³é”®è¯å’Œæå–çš„å…³é”®è¯
  const allKeywords = Array.from(new Set([...baseKeywords, ...contentKeywords]))

  console.log(`   âœ… æå–å®Œæˆ:`)
  console.log(`      - æ®µè½: ${uniqueParagraphs.length}`)
  console.log(`      - æ ‡é¢˜: ${uniqueHeadings.length}`)
  console.log(`      - å…³é”®è¯: ${allKeywords.length}`)

  return {
    name,
    description,
    filePath,
    paragraphs: uniqueParagraphs,
    headings: uniqueHeadings,
    keywords: allKeywords,
    totalParagraphs: uniqueParagraphs.length,
    totalHeadings: uniqueHeadings.length,
    totalKeywords: allKeywords.length
  }
}

/**
 * ä»æ–‡æœ¬ä¸­æå–å…³é”®è¯
 */
function extractKeywordsFromText(text: string): string[] {
  // ä¸­æ–‡åœç”¨è¯
  const commonWords = [
    'çš„', 'æ˜¯', 'åœ¨', 'å’Œ', 'ä¸', 'ä¸º', 'äº†', 'ç­‰', 'æ‚¨', 'æˆ‘ä»¬', 'å¯ä»¥',
    'è¿™ä¸ª', 'é‚£ä¸ª', 'ä¸€ä¸ª', 'ä»€ä¹ˆ', 'æ€ä¹ˆ', 'å¦‚ä½•', 'å°±æ˜¯', 'è¿˜æ˜¯', 'ä¸æ˜¯',
    'è¿™æ ·', 'é‚£æ ·', 'å·²ç»', 'æˆ–è€…', 'ä½†æ˜¯', 'è€Œä¸”', 'ç„¶å', 'æ‰€ä»¥', 'å› ä¸º',
    'å®ƒ', 'ä»–', 'å¥¹', 'æˆ‘', 'ä½ ', 'æˆ‘ä»¬', 'ä½ ä»¬', 'ä»–ä»¬', 'å¥¹ä»¬'
  ]

  // æå–ä¸­æ–‡è¯æ±‡ï¼ˆ2-10ä¸ªå­—ï¼‰
  const chineseWords = text.match(/[\u4e00-\u9fa5]{2,10}/g) || []

  // æå–è‹±æ–‡å•è¯ï¼ˆ3ä¸ªå­—æ¯ä»¥ä¸Šï¼‰
  const englishWords = text.match(/[a-zA-Z]{3,}/gi) || []

  // ç»Ÿè®¡è¯é¢‘
  const wordCount = new Map<string, number>()

  chineseWords.forEach(word => {
    if (!commonWords.includes(word)) {
      wordCount.set(word, (wordCount.get(word) || 0) + 1)
    }
  })

  englishWords.forEach(word => {
    const normalized = word.charAt(0).toUpperCase() + word.slice(1).toLowerCase()
    wordCount.set(normalized, (wordCount.get(normalized) || 0) + 1)
  })

  // è¿”å›å‡ºç°é¢‘ç‡æœ€é«˜çš„å‰30ä¸ªå…³é”®è¯
  return Array.from(wordCount.entries())
    .sort((a, b) => b[1] - a[1])
    .slice(0, 30)
    .map(([word]) => word)
}

/**
 * ä¿å­˜å†…å®¹åˆ°æ•°æ®åº“
 */
async function saveToDatabase(content: ExtractedContent) {
  console.log(`\nğŸ’¾ æ­£åœ¨ä¿å­˜åˆ°æ•°æ®åº“: ${content.name}`)

  try {
    const result = await prisma.spiderPoolSource.upsert({
      where: { name: content.name },
      create: {
        name: content.name,
        description: content.description,
        filePath: content.filePath,
        paragraphs: content.paragraphs,
        headings: content.headings,
        keywords: content.keywords,
        totalParagraphs: content.totalParagraphs,
        totalHeadings: content.totalHeadings,
        totalKeywords: content.totalKeywords,
        status: 'ACTIVE',
        isActive: true
      },
      update: {
        description: content.description,
        filePath: content.filePath,
        paragraphs: content.paragraphs,
        headings: content.headings,
        keywords: content.keywords,
        totalParagraphs: content.totalParagraphs,
        totalHeadings: content.totalHeadings,
        totalKeywords: content.totalKeywords,
        status: 'ACTIVE',
        isActive: true
      }
    })

    console.log(`   âœ… ä¿å­˜æˆåŠŸ (ID: ${result.id})`)
    return result
  } catch (error) {
    console.error(`   âŒ ä¿å­˜å¤±è´¥:`, error)
    throw error
  }
}

/**
 * ä¸»å‡½æ•°
 */
async function main() {
  console.log('ğŸ•·ï¸  å¼€å§‹ä»HTMLæ–‡ä»¶æå–å†…å®¹å¹¶å­˜å‚¨åˆ°æ•°æ®åº“...')
  console.log('=' .repeat(60))

  const results = []

  for (const file of HTML_FILES) {
    try {
      // æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
      if (!fs.existsSync(file.filePath)) {
        console.error(`\nâŒ æ–‡ä»¶ä¸å­˜åœ¨: ${file.filePath}`)
        continue
      }

      // æå–å†…å®¹
      const content = extractFromHTML(
        file.filePath,
        file.name,
        file.description,
        file.baseKeywords
      )

      // ä¿å­˜åˆ°æ•°æ®åº“
      const result = await saveToDatabase(content)
      results.push(result)
    } catch (error) {
      console.error(`\nâŒ å¤„ç† ${file.name} å¤±è´¥:`, error)
    }
  }

  console.log('\n' + '='.repeat(60))
  console.log('ğŸ“Š æ±‡æ€»ç»Ÿè®¡:')
  console.log(`   - æˆåŠŸå¤„ç†: ${results.length}/${HTML_FILES.length} ä¸ªæ–‡ä»¶`)
  console.log(`   - æ€»æ®µè½æ•°: ${results.reduce((sum, r) => sum + r.totalParagraphs, 0)}`)
  console.log(`   - æ€»æ ‡é¢˜æ•°: ${results.reduce((sum, r) => sum + r.totalHeadings, 0)}`)
  console.log(`   - æ€»å…³é”®è¯: ${results.reduce((sum, r) => sum + r.totalKeywords, 0)}`)

  console.log('\nâœ… æ‰€æœ‰å†…å®¹å·²æˆåŠŸå­˜å‚¨åˆ°æ•°æ®åº“ï¼')
  console.log('\nğŸ“‹ ä¸‹ä¸€æ­¥:')
  console.log('   1. ä½¿ç”¨è¿™äº›å†…å®¹æºç”Ÿæˆèœ˜è››æ± é¡µé¢')
  console.log('   2. åœ¨ç®¡ç†åå°æŸ¥çœ‹å†…å®¹æº: /spider-pool/sources')
  console.log('   3. è¿è¡Œèœ˜è››æ± é¡µé¢ç”Ÿæˆè„šæœ¬')
}

// æ‰§è¡Œä¸»å‡½æ•°
main()
  .then(async () => {
    await prisma.$disconnect()
    process.exit(0)
  })
  .catch(async (error) => {
    console.error('\nâŒ æ‰§è¡Œå¤±è´¥:', error)
    await prisma.$disconnect()
    process.exit(1)
  })
