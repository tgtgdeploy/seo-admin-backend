/**
 * ä»ä¸‰ä¸ª website HTML æ–‡ä»¶ä¸­æå–æ–‡ç« å’Œå…³é”®è¯
 * ç”¨äºç”Ÿæˆèœ˜è››æ± é¡µé¢
 */

import * as fs from 'fs'
import * as path from 'path'
import * as cheerio from 'cheerio'

// HTML æ–‡ä»¶è·¯å¾„é…ç½®
const HTML_FILES = [
  {
    name: 'website-1',
    path: '/home/ubuntu/WebstormProjects/seo-website-1/ç”µæŠ¥ä¸­æ–‡ç‰ˆ - Telegramå®˜ç½‘2.html',
    keywords: ['Telegram', 'ç”µæŠ¥', 'ç”µæŠ¥ä¸­æ–‡ç‰ˆ', 'Telegramä¸­æ–‡ç‰ˆ', 'TGçº¸é£æœº', 'Windows', 'Mac', 'Android', 'iOS']
  },
  {
    name: 'website-2',
    path: '/home/ubuntu/WebstormProjects/seo-website-2/çº¸é£æœº3.html',
    keywords: ['çº¸é£æœº', 'TGé£æœº', 'Telegram', 'ç”µæŠ¥ä¸‹è½½', 'å®‰å“ç‰ˆ', 'Android', 'Apk', 'ç”µè„‘ç‰ˆ', 'æ¡Œé¢ç‰ˆ']
  },
  {
    name: 'website-tg',
    path: '/home/ubuntu/WebstormProjects/seo-website-tg/TGä¸­æ–‡çº¸é£æœº1/Telegramå®˜ç½‘ - Telegramä¸‹è½½.html',
    keywords: ['Telegram', 'ç”µæŠ¥', 'Telegramä¸‹è½½', 'å®‰å…¨å³æ—¶é€šè®¯', 'éšç§', 'ç«¯åˆ°ç«¯åŠ å¯†', 'ç§˜å¯†èŠå¤©']
  }
]

interface ExtractedContent {
  website: string
  title: string
  description: string
  keywords: string[]
  paragraphs: string[]
  headings: string[]
  links: Array<{ text: string; href: string }>
}

/**
 * æå–å•ä¸ª HTML æ–‡ä»¶çš„å†…å®¹
 */
function extractFromHTML(filePath: string, websiteName: string, baseKeywords: string[]): ExtractedContent {
  const html = fs.readFileSync(filePath, 'utf-8')
  const $ = cheerio.load(html)

  // æå–æ ‡é¢˜
  const title = $('title').text() || ''

  // æå– meta description
  const description = $('meta[name="description"]').attr('content') || ''

  // æå–æ‰€æœ‰æ®µè½
  const paragraphs: string[] = []
  $('p, .content p, article p, .post-content p').each((_, el) => {
    const text = $(el).text().trim()
    if (text.length > 20) {  // è¿‡æ»¤å¤ªçŸ­çš„æ®µè½
      paragraphs.push(text)
    }
  })

  // æå–æ ‡é¢˜
  const headings: string[] = []
  $('h1, h2, h3, h4').each((_, el) => {
    const text = $(el).text().trim()
    if (text.length > 0) {
      headings.push(text)
    }
  })

  // æå–é“¾æ¥
  const links: Array<{ text: string; href: string }> = []
  $('a').each((_, el) => {
    const text = $(el).text().trim()
    const href = $(el).attr('href') || ''
    if (text.length > 0 && href && !href.startsWith('#')) {
      links.push({ text, href })
    }
  })

  // ä»å†…å®¹ä¸­æå–é¢å¤–çš„å…³é”®è¯
  const contentKeywords = extractKeywordsFromText([...paragraphs, ...headings].join(' '))

  return {
    website: websiteName,
    title,
    description,
    keywords: Array.from(new Set([...baseKeywords, ...contentKeywords])),
    paragraphs: paragraphs.slice(0, 50),  // é™åˆ¶æ•°é‡
    headings: headings.slice(0, 20),
    links: links.slice(0, 30)
  }
}

/**
 * ä»æ–‡æœ¬ä¸­æå–å…³é”®è¯
 */
function extractKeywordsFromText(text: string): string[] {
  const commonWords = ['çš„', 'æ˜¯', 'åœ¨', 'å’Œ', 'ä¸', 'ä¸º', 'äº†', 'ç­‰', 'æ‚¨', 'æˆ‘ä»¬', 'å¯ä»¥']
  const words = text.match(/[\u4e00-\u9fa5]{2,}/g) || []

  const wordCount = new Map<string, number>()
  words.forEach(word => {
    if (!commonWords.includes(word)) {
      wordCount.set(word, (wordCount.get(word) || 0) + 1)
    }
  })

  return Array.from(wordCount.entries())
    .sort((a, b) => b[1] - a[1])
    .slice(0, 20)
    .map(([word]) => word)
}

/**
 * ç”Ÿæˆèœ˜è››æ± JSONæ•°æ®
 */
async function generateSpiderPoolData() {
  console.log('ğŸ•·ï¸  å¼€å§‹æå–HTMLå†…å®¹ç”Ÿæˆèœ˜è››æ± æ•°æ®...\n')

  const allContent: ExtractedContent[] = []

  for (const file of HTML_FILES) {
    try {
      console.log(`ğŸ“„ å¤„ç† ${file.name}...`)
      const content = extractFromHTML(file.path, file.name, file.keywords)
      allContent.push(content)
      console.log(`âœ… ${file.name}: æå–åˆ° ${content.paragraphs.length} æ®µè½, ${content.headings.length} æ ‡é¢˜, ${content.keywords.length} å…³é”®è¯\n`)
    } catch (error) {
      console.error(`âŒ å¤„ç† ${file.name} å¤±è´¥:`, error)
    }
  }

  // ä¿å­˜åˆ°JSONæ–‡ä»¶
  const outputPath = path.join(__dirname, 'spider-pool-data.json')
  fs.writeFileSync(outputPath, JSON.stringify(allContent, null, 2), 'utf-8')

  console.log(`\nâœ… èœ˜è››æ± æ•°æ®å·²ä¿å­˜åˆ°: ${outputPath}`)
  console.log(`\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:`)
  console.log(`  - ç½‘ç«™æ•°é‡: ${allContent.length}`)
  console.log(`  - æ€»æ®µè½æ•°: ${allContent.reduce((sum, c) => sum + c.paragraphs.length, 0)}`)
  console.log(`  - æ€»å…³é”®è¯: ${allContent.reduce((sum, c) => sum + c.keywords.length, 0)}`)

  return allContent
}

/**
 * ç”Ÿæˆèœ˜è››æ± HTMLé¡µé¢
 */
function generateSpiderPoolHTML(data: ExtractedContent[], pageCount: number = 100): void {
  const outputDir = path.join(__dirname, 'spider-pool-pages')

  if (!fs.existsSync(outputDir)) {
    fs.mkdirSync(outputDir, { recursive: true })
  }

  console.log(`\nğŸŒ å¼€å§‹ç”Ÿæˆ ${pageCount} ä¸ªèœ˜è››æ± é¡µé¢...\n`)

  // åˆå¹¶æ‰€æœ‰å†…å®¹
  const allParagraphs = data.flatMap(d => d.paragraphs)
  const allKeywords = Array.from(new Set(data.flatMap(d => d.keywords)))
  const allHeadings = data.flatMap(d => d.headings)

  for (let i = 0; i < pageCount; i++) {
    // éšæœºé€‰æ‹©å†…å®¹
    const randomParagraphs = shuffle(allParagraphs).slice(0, 5 + Math.floor(Math.random() * 10))
    const randomKeywords = shuffle(allKeywords).slice(0, 10 + Math.floor(Math.random() * 10))
    const randomHeading = allHeadings[Math.floor(Math.random() * allHeadings.length)]

    const html = `<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>${randomHeading} | Telegramä¸­æ–‡èµ„è®¯</title>
    <meta name="description" content="${randomParagraphs[0].substring(0, 160)}">
    <meta name="keywords" content="${randomKeywords.join(', ')}">
    <style>
        body { font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto; padding: 20px; line-height: 1.6; }
        h1 { color: #0088cc; }
        h2 { color: #333; margin-top: 30px; }
        p { margin-bottom: 15px; color: #555; }
        .keywords { margin: 20px 0; padding: 15px; background: #f5f5f5; border-radius: 5px; }
        .keyword { display: inline-block; padding: 5px 10px; margin: 5px; background: #0088cc; color: white; border-radius: 3px; font-size: 14px; }
        footer { margin-top: 50px; padding-top: 20px; border-top: 1px solid #eee; text-align: center; color: #999; }
    </style>
</head>
<body>
    <h1>${randomHeading}</h1>

    <div class="keywords">
        <strong>ç›¸å…³å…³é”®è¯ï¼š</strong>
        ${randomKeywords.map(k => `<span class="keyword">${k}</span>`).join('')}
    </div>

    ${randomParagraphs.map((p, idx) => {
      if (idx % 3 === 0 && idx > 0) {
        return `<h2>${allHeadings[Math.floor(Math.random() * allHeadings.length)]}</h2><p>${p}</p>`
      }
      return `<p>${p}</p>`
    }).join('\n    ')}

    <footer>
        <p>Â© 2025 Telegramä¸­æ–‡èµ„è®¯ | <a href="https://telegram1688.com">ä¸»ç«™1</a> | <a href="https://telegram2688.com">ä¸»ç«™2</a> | <a href="https://telegramcnfw.com">ä¸»ç«™3</a></p>
    </footer>
</body>
</html>`

    const fileName = `page-${String(i + 1).padStart(4, '0')}.html`
    fs.writeFileSync(path.join(outputDir, fileName), html, 'utf-8')

    if ((i + 1) % 10 === 0) {
      console.log(`âœ… å·²ç”Ÿæˆ ${i + 1}/${pageCount} é¡µé¢`)
    }
  }

  console.log(`\nâœ… æˆåŠŸç”Ÿæˆ ${pageCount} ä¸ªèœ˜è››æ± é¡µé¢åˆ°: ${outputDir}`)
}

/**
 * æ•°ç»„éšæœºæ‰“ä¹±
 */
function shuffle<T>(array: T[]): T[] {
  const result = [...array]
  for (let i = result.length - 1; i > 0; i--) {
    const j = Math.floor(Math.random() * (i + 1));
    [result[i], result[j]] = [result[j], result[i]]
  }
  return result
}

// ä¸»å‡½æ•°
async function main() {
  try {
    const data = await generateSpiderPoolData()
    generateSpiderPoolHTML(data, 100)  // ç”Ÿæˆ100ä¸ªé¡µé¢

    console.log('\nğŸ‰ èœ˜è››æ± é¡µé¢ç”Ÿæˆå®Œæˆï¼')
    console.log('\nğŸ“‹ ä¸‹ä¸€æ­¥:')
    console.log('  1. å°† spider-pool-pages ç›®å½•ä¸Šä¼ åˆ°æœåŠ¡å™¨')
    console.log('  2. é…ç½® Nginx æŒ‡å‘è¯¥ç›®å½•')
    console.log('  3. æ¯ä¸ªé¡µé¢éƒ½åŒ…å«æŒ‡å‘ä¸‰ä¸ªä¸»ç«™çš„é“¾æ¥')
  } catch (error) {
    console.error('âŒ ç”Ÿæˆå¤±è´¥:', error)
    process.exit(1)
  }
}

main()
